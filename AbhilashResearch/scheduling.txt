1. Scheduling[edit]
In typical designs, a task has three states:

Running (executing on the CPU);
Ready (ready to be executed);
Blocked (waiting for an event, I/O for example).
Most tasks are blocked or ready most of the time because generally only one task can run at a time per CPU. The number of items in the ready queue can vary greatly, depending on the number of tasks the system needs to perform and the type of scheduler that the system uses. On simpler non-preemptive but still multitasking systems, a task has to give up its time on the CPU to other tasks, which can cause the ready queue to have a greater number of overall tasks in the ready to be executed state (resource starvation).
Usually the data structure of the ready list in the scheduler is designed to minimize the worst-case length of time spent in the scheduler's critical section, during which preemption is inhibited, and, in some cases, all interrupts are disabled. But the choice of data structure depends also on the maximum number of tasks that can be on the ready list.
If there are never more than a few tasks on the ready list, then a doubly linked list of ready tasks is likely optimal. If the ready list usually contains only a few tasks but occasionally contains more, then the list should be sorted by priority. That way, finding the highest priority task to run does not require iterating through the entire list. Inserting a task then requires walking the ready list until reaching either the end of the list, or a task of lower priority than that of the task being inserted.
Care must be taken not to inhibit preemption during this search. Longer critical sections should be divided into small pieces. If an interrupt occurs that makes a high priority task ready during the insertion of a low priority task, that high priority task can be inserted and run immediately before the low priority task is inserted.
The critical response time, sometimes called the flyback time, is the time it takes to queue a new ready task and restore the state of the highest priority task to running. In a well-designed RTOS, readying a new task will take 3 to 20 instructions per ready-queue entry, and restoration of the highest-priority ready task will take 5 to 30 instructions.
In more advanced systems, real-time tasks share computing resources with many non-real-time tasks, and the ready list can be arbitrarily long. In such systems, a scheduler ready list implemented as a linked list would be inadequate.

Algorithms[edit]
Some commonly used RTOS scheduling algorithms are:

Cooperative scheduling
Preemptive scheduling
Rate-monotonic scheduling
Round-robin scheduling
Fixed priority pre-emptive scheduling, an implementation of preemptive time slicing
Fixed-Priority Scheduling with Deferred Preemption
Fixed-Priority Non-preemptive Scheduling
Critical section preemptive scheduling
Static time scheduling
Earliest Deadline First approach
Stochastic digraphs with multi-threaded graph traversal

2. Most high-performance embedded systems do not need an expensive and full-functionality real-time operating system (RTOS). A dedicated scheduler such as those used in arbitration processes and traffic management is sufficient, extremely efficient, and has a low memory footprint. This approach is particularly preferred where memory size is limited and timing deadlines must be strictly enforced. 
Typical applications are in defence, aerospace, industrial, and automotive. There are a number of standard scheduling algorithms such as First­ Come, First ­Served (FCFS); Shortest Job First (SJF); Preemptive; and Round Robin. 
